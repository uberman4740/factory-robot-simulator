{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "mpl_cols = ['#3388dd', '#aa3377', '#449911']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys, inspect\n",
    "# realpath() will make your script run, even if you symlink it :)\n",
    "cmd_folder = os.path.realpath(os.path.abspath(\n",
    "        os.path.join(os.path.split(inspect.getfile( inspect.currentframe() ))[0],\n",
    "                     '..', '..', 'labeled-experiments', 'nn-classifiers')))\n",
    "print 'Added {0} to path.'.format(cmd_folder)\n",
    "if cmd_folder not in sys.path:\n",
    "    sys.path.insert(0, cmd_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import labeling_network as lbln\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "from labeling_network import FullyConnectedLayer, ConvPoolLayer\n",
    "\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(12345678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataPath = '../../../factory-robot-data/imgs_2015-10-18/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_action_data(filename, lower, upper):\n",
    "    action_file = open(filename)\n",
    "    lines = action_file.readlines()[lower:upper]\n",
    "    action_file.close()\n",
    "    data = np.asarray([int(l) for l in lines])\n",
    "    return data\n",
    "#     return data.reshape(upper - lower, n_direction_sensors * n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_actions(actions, n_actions):\n",
    "    result = []\n",
    "    for a in actions:\n",
    "        x = [0.0] * n_actions\n",
    "        x[a] = 1.0\n",
    "        result.append(x)\n",
    "    return np.asarray(result, dtype=theano.config.floatX)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def construct_training_examples(label_data, action_data, delta_t, n_past, n_future):\n",
    "    assert len(label_data) == len(action_data)\n",
    "    percept_len = label_data.shape[1]\n",
    "    n_actions = action_data.shape[1]\n",
    "    \n",
    "    xs_length = n_past*percept_len + (n_past + n_future - 1)*n_actions\n",
    "    t_length = n_future*percept_len\n",
    "    \n",
    "    training_data_xs = np.empty((len(label_data) - (n_past + n_future - 1)*delta_t, xs_length), \n",
    "                                dtype=theano.config.floatX)\n",
    "    training_data_ts = np.empty((len(label_data) - (n_past + n_future - 1)*delta_t, t_length),\n",
    "                                dtype=theano.config.floatX)\n",
    "    \n",
    "    for i in xrange(n_past * delta_t, len(label_data) - ((n_future-1)*delta_t + 1)):\n",
    "        example = []\n",
    "        for j in xrange(n_future):\n",
    "            training_data_ts[i - n_past*delta_t, j*percept_len: (j+1)*percept_len] = np.asarray(\n",
    "                label_data[i+j], dtype=theano.config.floatX)\n",
    "            \n",
    "            if (n_future - j) > 1:\n",
    "                xs_a = np.mean(action_data[i + j*delta_t: \n",
    "                                           i + (j+1)*delta_t] , axis=0)\n",
    "#                 print -(n_future-j-1)*n_actions\n",
    "#                 print -(n_future-j-2)*n_actions\n",
    "#                 print xs_a.shape\n",
    "#                 print\n",
    "                if n_future - j == 2:\n",
    "                    training_data_xs[i - n_past*delta_t, -(n_future-j-1)*n_actions:] = xs_a\n",
    "                else:\n",
    "                    training_data_xs[i - n_past*delta_t, -(n_future-j-1)*n_actions:\n",
    "                                                         -(n_future-j-2)*n_actions] = xs_a\n",
    "        for j in xrange(n_past):\n",
    "            xs_d = label_data[i - (n_past*delta_t) + j*delta_t]\n",
    "            xs_a = np.mean(action_data[i - (n_past*delta_t) + j*delta_t : \n",
    "                                       i - (n_past*delta_t) + (j+1)*delta_t] , axis=0)\n",
    "            training_data_xs[i - n_past*delta_t, j*(percept_len + n_actions):\n",
    "                                                 (j+1)*percept_len + j*n_actions] = xs_d\n",
    "            training_data_xs[i - n_past*delta_t, (j+1)*percept_len + j*n_actions:\n",
    "                                                 (j+1)*(percept_len + n_actions)] = xs_a\n",
    "             \n",
    "    return training_data_xs, training_data_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shuffle_data(data, rng):\n",
    "    xs, ts = data\n",
    "    index_set = np.asarray(range(len(xs)))\n",
    "    rng.shuffle(index_set)\n",
    "    return xs[index_set], ts[index_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_train = 150000\n",
    "n_valid = 5000\n",
    "n_test = 1000\n",
    "\n",
    "n_direction_sensors=9\n",
    "n_classes=2\n",
    "n_actions=3\n",
    "delta_t = 2\n",
    "n_past = 15\n",
    "n_future = 12\n",
    "\n",
    "\n",
    "lower = 0\n",
    "upper = n_train + n_valid + n_test + delta_t*n_past\n",
    "\n",
    "\n",
    "\n",
    "load_time_start = time.time()\n",
    "label_data_raw = lbln.load_labeling_data(dataPath+'labels.dat', lower, upper, mask=-1, \n",
    "                                         n_direction_sensors=n_direction_sensors, \n",
    "                                         n_classes=n_classes)\n",
    "actions_raw = convert_actions(load_action_data(dataPath+'actions.dat', lower, upper), \n",
    "                              n_actions=n_actions)\n",
    "\n",
    "all_data = construct_training_examples(label_data_raw, actions_raw, delta_t, n_past, n_future)\n",
    "all_data = shuffle_data(all_data, rng)\n",
    "\n",
    "training_xs = theano.shared(all_data[0][:n_train], borrow=True)\n",
    "training_ts = theano.shared(all_data[1][:n_train], borrow=True)\n",
    "\n",
    "valid_xs = theano.shared(all_data[0][n_train: n_train+n_valid], borrow=True)\n",
    "valid_ts = theano.shared(all_data[1][n_train: n_train+n_valid], borrow=True)\n",
    "\n",
    "test_xs = theano.shared(all_data[0][n_train+n_valid:], borrow=True)\n",
    "test_ts = theano.shared(all_data[1][n_train+n_valid:], borrow=True)\n",
    "\n",
    "\n",
    "print 'Loading data took {0:.5} seconds'.format(time.time() - load_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_frame(ax, percept, n_sensors, action, color=mpl_cols[0]):\n",
    "    percept_length = len(percept)\n",
    "    n_actions = len(action)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.bar(np.arange(percept_length), percept, \n",
    "           color=color,\n",
    "           edgecolor='none',\n",
    "           align='center')\n",
    "    ax.bar(np.arange(percept_length, percept_length + n_actions), action,\n",
    "          color=mpl_cols[1],\n",
    "          edgecolor='none',\n",
    "          align='center')\n",
    "    ax.set_xlim(-0.5, percept_length+n_actions-0.5)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.axvline(x=n_sensors-0.5)\n",
    "    ax.axvline(x=percept_length-0.5)\n",
    "\n",
    "def visualize_example(x, t, percept_length, n_sensors, n_actions, n_past, n_future):\n",
    "    fig = plt.figure(figsize=(6, 1*(n_past+1)))\n",
    "    for i in xrange(n_past):\n",
    "        ax = fig.add_subplot(n_past + n_future, 1, i + 1)\n",
    "        visualize_frame(ax, \n",
    "                        x[i*(percept_length + n_actions):\n",
    "                             (i + 1)*percept_length + i*n_actions],\n",
    "                        n_sensors,\n",
    "                        x[(i+1)*percept_length + i*n_actions:\n",
    "                          (i + 1)*(percept_length + n_actions)])\n",
    "    for i in xrange(n_future-1):\n",
    "        print x[n_past*(percept_length + n_actions) + i*n_actions:\n",
    "                n_past*(percept_length + n_actions) + (i + 1)*n_actions]      \n",
    "    \n",
    "    for i in xrange(n_future):\n",
    "        ax = fig.add_subplot(n_past + n_future, 1, n_past + i + 1)\n",
    "        visualize_frame(ax, \n",
    "                        t[i*percept_length: (i+1)*percept_length], \n",
    "                        n_sensors, \n",
    "                        np.zeros(n_actions), \n",
    "                        color=mpl_cols[2])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(9, 10, delta_t):\n",
    "    visualize_example(training_xs.get_value()[i], training_ts.get_value()[i], \n",
    "                      n_direction_sensors*n_classes, \n",
    "                      n_direction_sensors, \n",
    "                      n_actions, \n",
    "                      n_past, \n",
    "                      n_future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mini_batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network = lbln.Network([\n",
    "        FullyConnectedLayer(n_in=n_past*(n_direction_sensors*n_classes + n_actions) + (n_future-1)*n_actions, \n",
    "                            n_out=2000),\n",
    "        FullyConnectedLayer(n_in=2000, \n",
    "                            n_out=n_direction_sensors*n_classes*n_future)\n",
    "    ], mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network.SGD((training_xs, training_ts), \n",
    "            100, \n",
    "            mini_batch_size, \n",
    "            0.2, \n",
    "            (valid_xs, valid_ts), \n",
    "            (test_xs, test_ts),\n",
    "            'trained-networks/t_nf' + str(n_future) + '_np' + str(n_past) + '_' + datetime.datetime.now().strftime('%Y%m%d%H%M%S'),\n",
    "#             learning_curve_file_name='decoder_learning_curve_bigdata',\n",
    "#             rmsprop=(0.001, 0.9, 1e-6, 1.0)\n",
    "            adam=(0.0005, 0.1, 0.001, 1e-8)\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# network_filename = 'trained-networks/t_nf12_np15_20151019012110'\n",
    "\n",
    "n_eval = 7000\n",
    "\n",
    "simple_errors = []\n",
    "net_errors = []\n",
    "\n",
    "\n",
    "# net = lbln.Network.load_from_file(network_filename, mini_batch_size)\n",
    "net = network\n",
    "for x, t in zip(valid_xs.get_value()[:n_eval], valid_ts.get_value()[:n_eval]):\n",
    "    net_prediction = net.get_single_output(x)\n",
    "    net_errors.append(np.mean((net_prediction - t) ** 2))\n",
    "print 'mse net:    {0}'.format(np.mean(net_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = rng.randint(valid_xs.get_value().shape[0])\n",
    "ex = valid_xs.get_value()[i]\n",
    "visualize_example(ex, valid_ts.get_value()[i], \n",
    "                      n_direction_sensors*n_classes, \n",
    "                      n_direction_sensors, \n",
    "                      n_actions, \n",
    "                      n_past, \n",
    "                      n_future)\n",
    "\n",
    "visualize_example(ex, net.get_single_output(ex), \n",
    "                      n_direction_sensors*n_classes, \n",
    "                      n_direction_sensors, \n",
    "                      n_actions, \n",
    "                      n_past, \n",
    "                      n_future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prediction_net_filename = 'trained-networks/t_nf12_np15_20151019012110'\n",
    "visualization_net_filename = 'trained-networks/decoders/d_20151018193853'\n",
    "\n",
    "\n",
    "# prediction_net = lbln.Network.load_from_file(prediction_net_filename, mini_batch_size)\n",
    "prediction_net = network\n",
    "visualization_net = lbln.Network.load_from_file(visualization_net_filename, mini_batch_size)\n",
    "\n",
    "xs = valid_xs.get_value()\n",
    "ts = valid_ts.get_value()\n",
    "\n",
    "def extract_frames_from_x(x, n_direction_sensors, n_classes, n_actions, n_past):\n",
    "    return np.asarray([x[ i   *(n_direction_sensors*n_classes + n_actions):\n",
    "                         (i+1)*n_direction_sensors*n_classes + i*n_actions] for i in xrange(n_past)])\n",
    "def extract_frames_from_t(t, n_direction_sensors, n_classes, n_future):\n",
    "    return np.asarray([t[i*n_direction_sensors*n_classes:\n",
    "                         (i+1)*n_direction_sensors*n_classes] for i in xrange(n_future)])\n",
    "\n",
    "# print extract_frames_from_x(xs[0], n_direction_sensors, n_classes, n_actions, n_past)\n",
    "# print extract_frames_from_t(ts[0], n_direction_sensors, n_classes, n_past)\n",
    "\n",
    "\n",
    "def make_animation(filename, frames_past, frames_target, frames_predicted, visualization_net, n_direction_sensors):\n",
    "    import matplotlib.animation as manimation\n",
    "\n",
    "    FFMpegWriter = manimation.writers['ffmpeg']\n",
    "    metadata = dict(title='anim', artist='an',\n",
    "            comment='comment')\n",
    "    writer = FFMpegWriter(fps=1, metadata=metadata)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    def export_frame(fig, writer, frame_left, frame_right, n_direction_sensors, annotation=''):\n",
    "        fig.clear()\n",
    "\n",
    "        vis_l = (visualization_net.get_single_output(frame_left)).reshape(64, 64, 3)\n",
    "        vis_l = matplotlib.colors.hsv_to_rgb(vis_l)\n",
    "        \n",
    "        vis_r = (visualization_net.get_single_output(frame_right)).reshape(64, 64, 3)\n",
    "        vis_r = matplotlib.colors.hsv_to_rgb(vis_r)\n",
    "\n",
    "        ax1 = fig.add_subplot(2, 2, 1)\n",
    "        ax1.imshow(vis_l, interpolation='nearest')\n",
    "        ax1.text(0.5, -0.1, annotation,\n",
    "            verticalalignment='bottom', horizontalalignment='right',\n",
    "            transform=ax1.transAxes,\n",
    "            color='black', fontsize=7)\n",
    "\n",
    "\n",
    "        ax2 = fig.add_subplot(2, 2, 2)\n",
    "        ax2.imshow(vis_r, interpolation='nearest')\n",
    "        ax2.text(0.5, -0.1, annotation,\n",
    "            verticalalignment='bottom', horizontalalignment='right',\n",
    "            transform=ax2.transAxes,\n",
    "            color='black', fontsize=7)\n",
    "\n",
    "        ax3 = fig.add_subplot(2, 2, 3)\n",
    "        ax3.set_ylim(0, 1)\n",
    "        for j in xrange(len(frame_left) / n_direction_sensors):\n",
    "            ax3.bar(np.arange(n_direction_sensors) + j*n_direction_sensors,\n",
    "                    frame_left[j*n_direction_sensors:(j+1)*n_direction_sensors],\n",
    "                    color=mpl_cols[j % len(mpl_cols)],\n",
    "                    edgecolor='none')\n",
    "\n",
    "\n",
    "        ax4 = fig.add_subplot(2, 2, 4)\n",
    "        ax4.set_ylim(0, 1)\n",
    "        for j in xrange(len(frame_right) / n_direction_sensors):\n",
    "            ax4.bar(np.arange(n_direction_sensors) + j*n_direction_sensors,\n",
    "                    frame_right[j*n_direction_sensors:(j+1)*n_direction_sensors],\n",
    "                    color=mpl_cols[j % len(mpl_cols)],\n",
    "                    edgecolor='none')\n",
    "\n",
    "        ax1.set_frame_on(False)\n",
    "        ax1.get_yaxis().set_visible(False)\n",
    "        ax1.get_xaxis().set_visible(False)\n",
    "        ax2.set_frame_on(False)\n",
    "        ax2.get_yaxis().set_visible(False)\n",
    "        ax2.get_xaxis().set_visible(False)            \n",
    "        ax3.get_xaxis().set_visible(False)\n",
    "        ax4.get_yaxis().set_visible(False)\n",
    "        ax4.get_xaxis().set_visible(False)\n",
    "        writer.grab_frame()\n",
    "    \n",
    "    with writer.saving(fig, filename, 300):\n",
    "        for i in xrange(len(frames_past)):\n",
    "            export_frame(fig, writer, frames_past[i], frames_past[i], n_direction_sensors)\n",
    "        for i in xrange(len(frames_target)):\n",
    "            export_frame(fig, writer, frames_target[i], frames_predicted[i], n_direction_sensors, annotation='future')\n",
    "\n",
    "            \n",
    "            \n",
    "for test_index in range(5, 15):         \n",
    "    past_frames = extract_frames_from_x(xs[test_index], n_direction_sensors, n_classes, n_actions, n_past)\n",
    "    target_frames = extract_frames_from_t(ts[test_index], n_direction_sensors, n_classes, n_future)\n",
    "    predicted_frames = extract_frames_from_t(prediction_net.get_single_output(xs[test_index]), n_direction_sensors, n_classes, n_future)\n",
    "\n",
    "\n",
    "    make_animation('anims/anim{0}.mp4'.format(test_index), \n",
    "                   past_frames, \n",
    "                   target_frames,\n",
    "                   predicted_frames,  \n",
    "                   visualization_net,\n",
    "                   n_direction_sensors)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
