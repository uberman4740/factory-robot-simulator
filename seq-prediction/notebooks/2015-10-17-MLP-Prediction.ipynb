{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999;"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "mpl_cols = ['#3388dd', '#aa3377', '#449911']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added /Users/an/dev-repos/factory-robot-simulator/labeled-experiments/nn-classifiers to path.\n"
     ]
    }
   ],
   "source": [
    "import os, sys, inspect\n",
    "# realpath() will make your script run, even if you symlink it :)\n",
    "cmd_folder = os.path.realpath(os.path.abspath(\n",
    "        os.path.join(os.path.split(inspect.getfile( inspect.currentframe() ))[0],\n",
    "                     '..', '..', 'labeled-experiments', 'nn-classifiers')))\n",
    "print 'Added {0} to path.'.format(cmd_folder)\n",
    "if cmd_folder not in sys.path:\n",
    "    sys.path.insert(0, cmd_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with a CPU.  If this is not desired, then the modify network3.py to set\n",
      "the GPU flag to True.\n"
     ]
    }
   ],
   "source": [
    "import labeling_network as lbln\n",
    "from matplotlib import pyplot as plt\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "from labeling_network import FullyConnectedLayer, ConvPoolLayer\n",
    "\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(12345678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataPath = '../../../factory-robot-data/imgs_2015-10-17/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_action_data(filename, lower, upper):\n",
    "    action_file = open(filename)\n",
    "    lines = action_file.readlines()[lower:upper]\n",
    "    action_file.close()\n",
    "    data = np.asarray([int(l) for l in lines])\n",
    "    return data\n",
    "#     return data.reshape(upper - lower, n_direction_sensors * n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_actions(actions, n_actions):\n",
    "    result = []\n",
    "    for a in actions:\n",
    "        x = [0.0] * n_actions\n",
    "        x[a] = 1.0\n",
    "        result.append(x)\n",
    "    return np.asarray(result, dtype=theano.config.floatX)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def construct_training_examples(label_data, action_data, delta_t, n_past, n_future):\n",
    "    assert len(label_data) == len(action_data)\n",
    "    percept_len = label_data.shape[1]\n",
    "    n_actions = action_data.shape[1]\n",
    "    \n",
    "    xs_length = n_past*percept_len + (n_past + n_future - 1)*n_actions\n",
    "    t_length = n_future*percept_len\n",
    "    \n",
    "    training_data_xs = np.empty((len(label_data) - (n_past + n_future - 1)*delta_t, xs_length), \n",
    "                                dtype=theano.config.floatX)\n",
    "    training_data_ts = np.empty((len(label_data) - (n_past + n_future - 1)*delta_t, t_length),\n",
    "                                dtype=theano.config.floatX)\n",
    "    \n",
    "    for i in xrange(n_past * delta_t, len(label_data) - ((n_future-1)*delta_t + 1)):\n",
    "        example = []\n",
    "        for j in xrange(n_future):\n",
    "            training_data_ts[i - n_past*delta_t, j*percept_len: (j+1)*percept_len] = np.asarray(\n",
    "                label_data[i+j], dtype=theano.config.floatX)\n",
    "            \n",
    "            if (n_future - j) > 1:\n",
    "                xs_a = np.mean(action_data[i + j*delta_t: \n",
    "                                           i + (j+1)*delta_t] , axis=0)\n",
    "#                 print -(n_future-j-1)*n_actions\n",
    "#                 print -(n_future-j-2)*n_actions\n",
    "#                 print xs_a.shape\n",
    "#                 print\n",
    "                if n_future - j == 2:\n",
    "                    training_data_xs[i - n_past*delta_t, -(n_future-j-1)*n_actions:] = xs_a\n",
    "                else:\n",
    "                    training_data_xs[i - n_past*delta_t, -(n_future-j-1)*n_actions:\n",
    "                                                         -(n_future-j-2)*n_actions] = xs_a\n",
    "        for j in xrange(n_past):\n",
    "            xs_d = label_data[i - (n_past*delta_t) + j*delta_t]\n",
    "            xs_a = np.mean(action_data[i - (n_past*delta_t) + j*delta_t : \n",
    "                                       i - (n_past*delta_t) + (j+1)*delta_t] , axis=0)\n",
    "            training_data_xs[i - n_past*delta_t, j*(percept_len + n_actions):\n",
    "                                                 (j+1)*percept_len + j*n_actions] = xs_d\n",
    "            training_data_xs[i - n_past*delta_t, (j+1)*percept_len + j*n_actions:\n",
    "                                                 (j+1)*(percept_len + n_actions)] = xs_a\n",
    "             \n",
    "    return training_data_xs, training_data_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shuffle_data(data, rng):\n",
    "    xs, ts = data\n",
    "    index_set = np.asarray(range(len(xs)))\n",
    "    rng.shuffle(index_set)\n",
    "    return xs[index_set], ts[index_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data took 1.0568 seconds\n"
     ]
    }
   ],
   "source": [
    "n_train = 10\n",
    "n_valid = 5000\n",
    "n_test = 1000\n",
    "\n",
    "n_direction_sensors=7\n",
    "n_classes=2\n",
    "n_actions=3\n",
    "delta_t = 2\n",
    "n_past = 12\n",
    "n_future = 5\n",
    "\n",
    "\n",
    "lower = 0\n",
    "upper = n_train + n_valid + n_test + delta_t*n_past\n",
    "\n",
    "\n",
    "\n",
    "load_time_start = time.time()\n",
    "label_data_raw = lbln.load_labeling_data(dataPath+'labels.dat', lower, upper, mask=-1, \n",
    "                                         n_direction_sensors=n_direction_sensors, \n",
    "                                         n_classes=n_classes)\n",
    "actions_raw = convert_actions(load_action_data(dataPath+'actions.dat', lower, upper), \n",
    "                              n_actions=n_actions)\n",
    "\n",
    "all_data = construct_training_examples(label_data_raw, actions_raw, delta_t, n_past, n_future)\n",
    "all_data = shuffle_data(all_data, rng)\n",
    "\n",
    "training_xs = theano.shared(all_data[0][:n_train], borrow=True)\n",
    "training_ts = theano.shared(all_data[1][:n_train], borrow=True)\n",
    "\n",
    "valid_xs = theano.shared(all_data[0][n_train: n_train+n_valid], borrow=True)\n",
    "valid_ts = theano.shared(all_data[1][n_train: n_train+n_valid], borrow=True)\n",
    "\n",
    "test_xs = theano.shared(all_data[0][n_train+n_valid:], borrow=True)\n",
    "test_ts = theano.shared(all_data[1][n_train+n_valid:], borrow=True)\n",
    "\n",
    "\n",
    "print 'Loading data took {0:.5} seconds'.format(time.time() - load_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_frame(ax, percept, n_sensors, action, color=mpl_cols[0]):\n",
    "    percept_length = len(percept)\n",
    "    n_actions = len(action)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.bar(np.arange(percept_length), percept, \n",
    "           color=color,\n",
    "           edgecolor='none',\n",
    "           align='center')\n",
    "    ax.bar(np.arange(percept_length, percept_length + n_actions), action,\n",
    "          color=mpl_cols[1],\n",
    "          edgecolor='none',\n",
    "          align='center')\n",
    "    ax.set_xlim(-0.5, percept_length+n_actions-0.5)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.axvline(x=n_sensors-0.5)\n",
    "    ax.axvline(x=percept_length-0.5)\n",
    "\n",
    "def visualize_example(x, t, percept_length, n_sensors, n_actions, n_past, n_future):\n",
    "    fig = plt.figure(figsize=(6, 1*(n_past+1)))\n",
    "    for i in xrange(n_past):\n",
    "        ax = fig.add_subplot(n_past + n_future, 1, i + 1)\n",
    "        visualize_frame(ax, \n",
    "                        x[i*(percept_length + n_actions):\n",
    "                             (i + 1)*percept_length + i*n_actions],\n",
    "                        n_sensors,\n",
    "                        x[(i+1)*percept_length + i*n_actions:\n",
    "                          (i + 1)*(percept_length + n_actions)])\n",
    "    for i in xrange(n_future-1):\n",
    "        print x[n_past*(percept_length + n_actions) + i*n_actions:\n",
    "                n_past*(percept_length + n_actions) + (i + 1)*n_actions]      \n",
    "    \n",
    "    for i in xrange(n_future):\n",
    "        ax = fig.add_subplot(n_past + n_future, 1, n_past + i + 1)\n",
    "        visualize_frame(ax, \n",
    "                        t[i*percept_length: (i+1)*percept_length], \n",
    "                        n_sensors, \n",
    "                        np.zeros(n_actions), \n",
    "                        color=mpl_cols[2])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABGCAYAAABv7kdbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAAgVJREFUeJzt3eFtm1AYhtH7RZ0kM2SVzJKO0M7SVTxDVvn6p5WqBHCE\n4YXa5/wEG10s9AhdwFR3DwAyno4eAMAjEV2AINEFCBJdgCDRBQgSXYCgb0srq8r9ZAArdHdNLV+M\n7p8vbj8a7krVGA4Trvl7nPx6+X7Tdl4vPzYa0X6qJns7xjC9ABAlugBBV6cXOJeXn++rv3t5e95w\nJMAaznQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJE\nFyBIdAGCRBcgyOt6dnbL63XG2PcVO1uP7UzbO/PY9t7emceGM12AqOru+ZVV8ysBmNXdNbV8MboA\nbMv0AkCQ6AIEiS5A0OItYy6kAawzdyHt6n26R15oqxrjka7zfbwf0v2NcKy1Daqa7O0Yw/QCQJTo\nAgSJLkDQof+98O8c5uXteeIZb3OawH1xpgsQJLoAQaILEOT/dDmVj/P8cG+c6QIEiS5AkOgCBIku\nQJDoAgSJLkCQ6AIEiS5AkOgCBHki7UCevoLH40wXIEh0AYJEFyDo9HO6194u8ZVlt3zmaHvu2+c3\ndYxPnznaVvu29nc7o+QxcYbfYM99O+LtNaePLjyS/+FEgNuYXgAIqu6eX1k1vxKAWd1dU8sXowvA\ntkwvAASJLkCQ6AIEiS5AkOgCBP0GeLTECTGByZ8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cb887d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in xrange(0, 1):\n",
    "    fig = plt.figure(figsize=(6, 1))\n",
    "    ax = fig.add_subplot(211)\n",
    "    ax2= fig.add_subplot(212)\n",
    "    print i\n",
    "    visualize_frame(ax, label_data_raw[i + delta_t*n_past], 7, actions_raw[i])\n",
    "    visualize_frame(ax2, training_ts.get_value()[i], 7, np.zeros(3))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.]\n",
      "[ 1.  0.  0.]\n",
      "[ 1.  0.  0.]\n",
      "[ 1.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAALjCAYAAACxoNYvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEBNJREFUeJzt3dFx3MaCQNHuLUfgEBwDU3AISsEpmCHIKTgFheAUGIND\ncAq9P8sqlT0YaGfAS5BzzuegBg+WwMt+rW5grrUGAI3/ee8LAHgkogsQEl2AkOgChEQXIPTTtYNz\nTksbAG6w1pqXPr8a3f/74vFXw6cy5xhuE/a83iffnp7vOs+Xl68HXdHbmfNib8cYphcAUqILEBJd\ngJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDo\nAoR2X0z5Fp7++Puu77/8/stBVwLQMtIFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCL3LjjQ+\np6N3Gt5zviPPdel8j8Sf3bFEF25wpl8w/z6fSJ6b6QWAkOgChOZaa/vgnNsHAdi01pqXPr8aXQCO\nZXoBICS6ACHRBQiJLkBIdAFCV3ekWTIGcJutJWO724AtKWPPnGO4Tdjzep98e3q+6zxfXr4edEVv\nZ86LvR1jmF4ASIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcg\nJLoAIdEFCIkuQEh0AUKiCxDafTHlR/D0x983f/fl918OvBKA64x0AUKiCxASXYCQ6AKERBcgJLoA\nIdEFCIkuQEh0AUKfYkca53DPzsAx/rs78Midhme6tkvn43GILpzAkRH3C+bcTC8AhEQXIDTXWtsH\n59w+CMCmtda89PnV6AJwLNMLACHRBQiJLkBIdAFCogsQEl2A0NVtwNbpAtxma53u7rMXrONlz5xj\nuE3Y83qffHt6vus8X16+HnRFb2fOi70dY5heAEiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJ\nLkDoh17B7hXMAMcw0gUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUI/dCOtEdi9x3wlox0AUKi\nCxASXYCQ6AKERBcgJLoAIdEFCIkuQMjmCE7rno0q/96kcvSml7Ofj/MSXQ4jHOfgF8K5mV4ACIku\nQGiutbYPzrl9EIBNa6156fOr0QXgWKYXAEKiCxASXYCQ6AKERBcgJLoAoavbgK3TBbjN1jrd3Wcv\nWMfLnjnHcJuw5/U++fb0fNd5vrx8PeiK3s6cF3s7xjC9AJASXYCQ6AKERBcgJLoAIdEFCIkuQEh0\nAULv8mJKL7oDHpWRLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQepdnLzwSz5kA\nvmekCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUI2R/AQjt6kcubz2ZBzbqLLYc4UIuE4jogfy/QC\nQEh0AUKiCxCaa63tg3NuHwRg01prXvr8anQBOJbpBYCQ6AKERBcgJLoAIdEFCF3dBmzJGMBttpaM\n7T57wZIy9sw5htuEPa/3yben57vO8+Xl60FX9HbmvNjbMYbpBYCU6AKERBcgJLoAIdEFCIkuQEh0\nAUKiCxASXYCQ6AKEPsUr2L2qG/gojHQBQqILEBJdgJDoAoREFyAkugAh0QUIfYp1uo/EmmT42Ix0\nAUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxCyDRhucM927DH+uyX7yPOd+doQXU7syOdM\nCAdnIbocRthgnzldgJDoAoTmWmv74JzbBwHYtNaalz6/Gl0AjmV6ASAkugAh0QUIiS5ASHQBQld3\npFkyBnCbrSVju9uALSljz5xjuE3Y83qffHt6vus8X16+HnRFb2fOi70dY5heAEiJLkBIdAFCogsQ\nEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChHYf7TjGGE9//H3X/8jL77/c9f3SI/23\nAj0jXYDQD410+ZyM6qFnpAsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXIOSB\nN3ACRz586OgHGXkw0rFEl4cgRJyF6HKYM4VN1DirTxFdP5zAR+Ef0gBCc621fXDO7YMAbFprzUuf\nX40uAMcyvQAQEl2AkOgChEQXICS6AKGrmyMsGQO4zdaSsd0daZaUsWfOMdwm7Hm9T749Pd91ni8v\nXw+6orcz58XejjFMLwCkRBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcg9EMvpvS6aYBjGOkC\nhEQXICS6ACHRBQiJLkDoh1YvcDsrP4DvGekChN5lpGv0BzwqI12AkOgChEQXICS6ACHRBQiJLkBI\ndAFCogsQEl2AkOgChDzwBj6Zo7fZ27Z/LNH9FzfY7R7pz07YuJXoclr3hEjUOCtzugAh0QUIzbXW\n9sE5tw8CsGmtNS99fjW6ABzL9AJASHQBQqILEBJdgJDoAoSu7kizZAzgNltLxna3AVtSxp45x3Cb\nsOf1Pvn29HzXeb68fD3oit7OnBd7O8YwvQCQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCP/SONC/h\nAziGkS5ASHQBQqILEBJdgJDoAoR+aPUC53HPyg+rPuD9GekChEQXICS6AKFPMadrnhP4KIx0AUKi\nCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKfYkfamXkfHPA9I12AkJEuhznTW6M/2v9DOPLP7kx/\nD5fO9+hEl4cgRJyF6QWAkOgChOZaa/vgnNsHAdi01pqXPr8aXQCOZXoBICS6ACHRBQiJLkBIdAFC\nV3ekWTIGcJutJWO724AtKWPPnGO4Tdjzep98e3q+6zxfXr4edEVvZ86LvR1jmF4ASIkuQEh0AUKi\nCxASXYCQ6AKEvDnigXn7AfSMdAFCogsQEl2A0LvM6Z7pzazmJYGSkS5ASHQBQqILEBJdgJDoAoRE\nFyAkugAhz174F88jAN6SkS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEPLsBQ5z\n5nffPdIzNc7093DpfI9OdOEGwsatRPeD8eZj+NjM6QKE5lpr++Cc2wcB2LTWmpc+vxpdAI5legEg\nJLoAIdEFCIkuQEh0AUJXN0dYMgZwm60lY7s70iwpY8+cY7hN2PN6n3x7er7rPF9evh50RW9nzou9\nHWOYXgBIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5A6FO8mNLLGoGPwkgXICS6ACHRBQh9\nijndI90zPzyGOWLgOiNdgJCR7hszcga+Z6QLEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJd\ngJDoAoREFyAkugAhTxnjMEc/Ue3Id9+d6doune/MHum/tSC6cAJHhk0kz830AkBIdAFCc621fXDO\n7YMAbFprzUufX40uAMcyvQAQEl2AkOgChEQXICS6AKGrO9IsGQO4zdaSsd1twJaUsWfOMdwm7Hm9\nT749Pd91ni8vXw+6orcz58XejjFMLwCkRBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQd6T9i/dLAW/J\nSBcgJLoAIdEFCIkuQEh0AUJWL3ww96yusLIC3p+RLkDISPeNWfcLfM9IFyAkugAh0QUIiS5ASHQB\nQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQp4yxmGOfqLakc8OPtO1FefjvEQXPhm/EM7N9AJA\nSHQBQnOttX1wzu2DAGxaa81Ln1+NLgDHMr0AEBJdgJDoAoREFyAkugChqzvSLBkDuM3WkrHdbcCW\nlLFnzjHcJux5vU++PT3fdZ4vL18PuqK3M+fF3o4xTC8ApEQXICS6ACHRBQiJLkBIdAFC3hzxxjx1\nH/iekS5ASHQBQqILEBJdgJDoAoREFyAkugAh63Q/mHvW/VrzC+/PSBcgZKT7wOyWg56RLkBIdAFC\nogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChDxljMMc/dSyI58dfKZrK87HeYku\nfDJ+IZyb6QWAkOgChOZaa/vgnNsHAdi01pqXPr8aXQCOZXoBICS6ACHRBQiJLkBIdAFCogsQuroN\n2DpdgNtsrdPdffaCdbzsmXMMtwl7Huk+mfNib8cYphcAUqILEBJdgJDoAoQ8xPyD+fXPn2/+7l+/\n/XPYuS6dD9hnpAsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJ\nLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCP733BcCWX//8+ebv/vXbP4ed66Od7+hr\n41iiy2H8sH9O/l6PZXoBICS6AKG51to+OOf2QQA2rbXmpc+vRheAY5leAAiJLkBIdAFCogsQEl2A\nkOgChK5uA7ZOF+A2W+t0d5+9YB3v53XUnvo5x3CbsOeR7pM5L/Z2jGF6ASAlugAh0QUIiS5ASHQB\nQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqIL\nEBJdgJDoAoR+eu8L4P/n1z9/vvm7f/32z4FXAtzCSBcgJLoAIdEFCIkuQMg/pPEQ7vkHyDH++4+Q\nZz7fma8N0eVAZ/ph94POWZleAAiJLkBIdAFCc621fXDO7YMAbFprzUufX40uAMcyvQAQEl2AkOgC\nhEQXICS6AKGr24AtGQO4zdaSsd1nL1hSxp45x3CbsOeR7pM5L/Z2jGF6ASAlugAh0QUIiS5ASHQB\nQqILEBJdgJDoAoREFyAkugAhr2B/YEe/Mh3YZ6QLEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqIL\nEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDX9cANjn7V0ZHnO/O1Iboc6Ew/7MLBWZle\nAAiJLkBIdAFCc621fXDO7YMAbFprzUufX40uAMcyvQAQEl2AkOgChEQXICS6AKGr24AtGQO4zdaS\nsd1nL1hSxp45x3CbsOeR7pM5L/Z2jGF6ASAlugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh\n0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUI\niS5ASHQBQj+99wXAR/Trnz/f9f2/fvvnzc535mtDdDnQmX7YhYOzMr0AEDLSfWBGf9Az0gUIzbXW\n9sE5tw8CsGmtNS99fjW6ABzL9AJASHQBQqILEBJdgJDoAoSubo6wZAzgNltLxnZ3pFlSxp45x3Cb\nsOeR7pM5L/Z2jGF6ASAlugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqIL\nEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQj+99wUA\nY/z65893ff+v3/55k3O9xfkenehymDP/cAoRZyG6nNY9YRM1zsqcLkBIdAFCc621fXDO7YMAbFpr\nzUufX40uAMcyvQAQEl2AkOgChEQXICS6AKH/Bbthcj7+wAOYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cb7a310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in xrange(0, 1, delta_t):\n",
    "    visualize_example(training_xs.get_value()[i], training_ts.get_value()[i], \n",
    "                      n_direction_sensors*n_classes, \n",
    "                      n_direction_sensors, \n",
    "                      n_actions, \n",
    "                      n_past, \n",
    "                      n_future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mini_batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network = lbln.Network([\n",
    "        FullyConnectedLayer(n_in=n_past*(n_direction_sensors*n_classes + n_actions) + (n_future-1)*n_actions, \n",
    "                            n_out=300),\n",
    "        FullyConnectedLayer(n_in=300, \n",
    "                            n_out=n_direction_sensors*n_classes*n_future)\n",
    "    ], mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network.SGD((training_xs, training_ts), \n",
    "            100, \n",
    "            mini_batch_size, \n",
    "            0.2, \n",
    "            (valid_xs, valid_ts), \n",
    "            (test_xs, test_ts),\n",
    "            'trained-networks/t_nf' + str(n_future) + '_np' + str(n_past) + '_' + datetime.datetime.now().strftime('%Y%m%d%H%M%S'),\n",
    "#             learning_curve_file_name='decoder_learning_curve_bigdata',\n",
    "            rmsprop=(0.001, 0.9, 1e-6, 1.0)\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network: 2 layers loaded.\n",
      "mse net:    0.00561058402274\n"
     ]
    }
   ],
   "source": [
    "network_filename = 'trained-networks/t_nf5_np12_20151018055615'\n",
    "\n",
    "n_eval = 7000\n",
    "\n",
    "simple_errors = []\n",
    "net_errors = []\n",
    "\n",
    "\n",
    "net = network.load_from_file(network_filename, mini_batch_size)\n",
    "for x, t in zip(valid_xs.get_value()[:n_eval], valid_ts.get_value()[:n_eval]):\n",
    "#     simple_prediction = x[-(n_direction_sensors*n_classes + n_actions) : -n_actions]\n",
    "    net_prediction = net.get_single_output(x)\n",
    "#     simple_errors.append(np.mean((simple_prediction - t) ** 2))\n",
    "    net_errors.append(np.mean((net_prediction - t) ** 2))\n",
    "#     print prediction\n",
    "#     print t\n",
    "#     print (prediction - t) ** 2\n",
    "#     print np.mean((prediction-t) ** 2)\n",
    "# print 'mse simple: {0}'.format(np.mean(simple_errors))\n",
    "print 'mse net:    {0}'.format(np.mean(net_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  1.]\n",
      "[ 0.  0.  1.]\n",
      "[ 0.  0.  1.]\n",
      "[ 0.  0.  1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAALjCAYAAACxoNYvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAgSXYAg0QUIEl2AINEFCPp/4odjWE+DbkAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e1c5cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  1.]\n",
      "[ 0.  0.  1.]\n",
      "[ 0.  0.  1.]\n",
      "[ 0.  0.  1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAALjCAYAAACxoNYvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10da54250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = rng.randint(valid_xs.get_value().shape[0])\n",
    "ex = valid_xs.get_value()[i]\n",
    "visualize_example(ex, valid_ts.get_value()[i], \n",
    "                      n_direction_sensors*n_classes, \n",
    "                      n_direction_sensors, \n",
    "                      n_actions, \n",
    "                      n_past, \n",
    "                      n_future)\n",
    "\n",
    "visualize_example(ex, net.get_single_output(ex), \n",
    "                      n_direction_sensors*n_classes, \n",
    "                      n_direction_sensors, \n",
    "                      n_actions, \n",
    "                      n_past, \n",
    "                      n_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (6.0, 6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data_xs = test_data[0].get_value()\n",
    "test_data_ts = test_data[1].get_value()\n",
    "\n",
    "valid_data_xs = valid_data[0].get_value()\n",
    "valid_data_ts = valid_data[1].get_value()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine all Losses on test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_classification(index, n_classes=5, n_directions=5):\n",
    "#     print 'Target:    ', classifications[index][1]\n",
    "#     print 'Prediction:', classifications[index][2]\n",
    "    print 'Loss:      ', classifications[index][3]\n",
    "    plt.imshow(classifications[index][0].reshape(64, 64, 3), interpolation='nearest')\n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    ax_left = fig.add_subplot(121)\n",
    "    ax_right = fig.add_subplot(122)\n",
    "    ax_left.set_ylim(0,1)\n",
    "    ax_right.set_ylim(0,1)\n",
    "    bar_width = 0.1\n",
    "    chart_colors = ['#ff2222', '#3399bb', '#55aa22', '#bbee33', '#881144']\n",
    "    for i in xrange(n_classes):\n",
    "        ax_left.bar(np.arange(n_directions)-(n_directions/2) + (i - n_directions/2.0 + 0.5)*bar_width,\n",
    "               classifications[index][1][i*n_directions: (i+1)*n_directions],\n",
    "               bar_width,\n",
    "               color=chart_colors[i],\n",
    "               align='center')\n",
    "        ax_right.bar(np.arange(n_directions)-(n_directions/2) + (i - n_directions/2.0 + 0.5)*bar_width,\n",
    "               classifications[index][2][i*n_directions: (i+1)*n_directions],\n",
    "               bar_width,\n",
    "               color=chart_colors[i],\n",
    "               align='center')\n",
    "    plt.show()\n",
    "    print '---------'\n",
    "        \n",
    "\n",
    "\n",
    "# Determine all errors on the test images\n",
    "classifications = []\n",
    "for x, t in zip(valid_data_xs, valid_data_ts):\n",
    "    prediction = network.get_single_output(x)\n",
    "    error = np.mean((t - prediction) ** 2)\n",
    "    classifications.append((x, t, prediction, error))\n",
    "\n",
    "print '--- Worst predictions: ---'\n",
    "classifications = sorted(classifications, key = lambda (x, t, p, e): e, reverse=True)\n",
    "print_classification(0)\n",
    "print_classification(1)\n",
    "\n",
    "print '\\n\\n'\n",
    "print '--- Median prediction ---'\n",
    "n_displayed_median = 8\n",
    "for i in xrange(-n_displayed_median/2, n_displayed_median/2):\n",
    "    print_classification(len(classifications)/2 + i)\n",
    "    \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.bar(np.arange(len(classifications)), np.asarray(classifications)[:, 3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False positives / negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print '--- FALSE POSITIVES ---'\n",
    "classifications = sorted(classifications, key = lambda (x, t, p, e): np.mean(p - t), reverse=True)\n",
    "print_classification(0)\n",
    "print_classification(1)\n",
    "\n",
    "\n",
    "print '\\n\\n\\n\\n--- FALSE NEGATIVES ---'\n",
    "classifications = sorted(classifications, key = lambda (x, t, p, e): np.mean(t - p), reverse=True)\n",
    "print_classification(0)\n",
    "print_classification(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find images displaying high signal w.r.t. target of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HUMAN, PICKUP, TERMINAL, FIRE, WALL = range(5)\n",
    "\n",
    "chosen_target = FIRE\n",
    "high_signal_indices = [i for (i, c) in enumerate(classifications)\n",
    "                       if np.mean(c[1][chosen_target*5: (chosen_target+1)*5]) > 0.2]\n",
    "\n",
    "print '%d high signal images.' % len(high_signal_indices)\n",
    "\n",
    "for i in np.asarray(high_signal_indices)[np.random.choice(np.arange(len(high_signal_indices)),\n",
    "                                              size=10,\n",
    "                                              replace=False)]:\n",
    "    print_classification(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## AVERAGE SQUARED MAGNITUDE OF SENSOR VALUES:\n",
    "\n",
    "test_targets = train_data[1].get_value()\n",
    "print 'Loss of mean-regressor: %f' % np.mean((test_targets - np.mean(test_targets)) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "\n",
    "def load_training_img(index):\n",
    "    return scipy.misc.imread(dataPath + 'capture' + str(index).zfill(6) + '.png')[:,:,:-1]\n",
    "\n",
    "def load_labeling_data(lower, upper):    \n",
    "    labels = open(dataPath + 'labels.dat')\n",
    "    lines = labels.readlines()[lower:upper]\n",
    "\n",
    "    data = np.asarray([[float(d) for d in l.split(',')[:-1]] for l in lines])\n",
    "    return data.reshape(upper-lower, 5, 5)\n",
    "\n",
    "pic_ind = 5\n",
    "\n",
    "img = load_training_img(pic_ind)\n",
    "\n",
    "plt.imshow(img, interpolation='nearest')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "data = load_labeling_data(pic_ind, pic_ind+1)\n",
    "label_titles = ['Humanoid', 'PickupBox', 'Terminal', 'Fire', 'Walls']\n",
    "\n",
    "for d, t in zip(data[0], label_titles):\n",
    "    ax = plt.subplot()    \n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.set_xlim(-2.5, 2.5)\n",
    "    ax.set_title(t)\n",
    "    barchart = ax.bar(np.arange(5) - 2, d, align='center')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
